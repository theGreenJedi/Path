1
00:00:08,684 --> 00:00:11,363
The common work flow is to read
your data into a DataFrame

2
00:00:11,363 --> 00:00:14,042
then reduce this DataFrame
to the particular columns or

3
00:00:14,042 --> 00:00:17,260
rows that you're interested
in working with.

4
00:00:17,260 --> 00:00:20,500
As you've seen, the Panda's toolkit
tries to give you views on a DataFrame.

5
00:00:20,500 --> 00:00:24,650
This is much faster than copying data and
much more memory efficient too.

6
00:00:25,740 --> 00:00:28,800
But it does mean that if you're
manipulating the data you have to be aware

7
00:00:28,800 --> 00:00:31,430
that any changes to
the DataFrame you're working on

8
00:00:31,430 --> 00:00:34,630
may have an impact on the base
data frame you used originally.

9
00:00:35,810 --> 00:00:39,380
Here's an example using our same
purchasing DataFrame from earlier.

10
00:00:39,380 --> 00:00:44,460
We can create a series based on just the
cost category using the square brackets.

11
00:00:44,460 --> 00:00:48,540
Then we can increase the cost in
this series using broadcasting.

12
00:00:48,540 --> 00:00:53,620
Now if we look at our original DataFrame,
we see those costs have risen as well.

13
00:00:53,620 --> 00:00:56,150
This is an important
consideration to watch out for.

14
00:00:56,150 --> 00:00:58,113
If you want to explicitly use a copy,

15
00:00:58,113 --> 00:01:02,511
then you should consider calling the copy
method on the DataFrame for it first.

16
00:01:04,327 --> 00:01:08,930
In this course, we'll be largely using
smaller, moderate-sized datasets.

17
00:01:08,930 --> 00:01:09,700
As I mentioned,

18
00:01:09,700 --> 00:01:14,470
a common workflow is to read the dataset
in, usually from some external file.

19
00:01:14,470 --> 00:01:18,630
We saw previously how you can do this
using Python, and lists, and dictionaries.

20
00:01:18,630 --> 00:01:22,190
You can imagine how you might use those
dictionaries to create a Pandas DataFrame.

21
00:01:23,310 --> 00:01:25,620
Thankfully, Pandas has
built-in support for

22
00:01:25,620 --> 00:01:29,140
delimited files such as CSV
files as well as a variety of

23
00:01:29,140 --> 00:01:33,850
other data formats including relational
databases, Excel, and HTML tables.

24
00:01:34,990 --> 00:01:37,440
I've saved a CSV file called olympics.csv,

25
00:01:37,440 --> 00:01:41,940
which has data from Wikipedia that
contains a summary list of the medal

26
00:01:41,940 --> 00:01:43,690
various countries have
won at the Olympics.

27
00:01:44,950 --> 00:01:48,180
We can take a look at this file
using the shell command cat.

28
00:01:48,180 --> 00:01:51,110
Which we can invoke directly
using the exclamation point.

29
00:01:52,110 --> 00:01:55,550
What happens here is that when the Jupyter
notebook sees a line beginning with

30
00:01:55,550 --> 00:02:00,632
an exclamation mark, it sends the rest of
the line to the operating system shell for

31
00:02:00,632 --> 00:02:01,540
evaluation.

32
00:02:01,540 --> 00:02:05,690
So cat works on Linux and Macs,
as well as in the Coursera platform, but

33
00:02:05,690 --> 00:02:07,610
might not work on Windows.

34
00:02:07,610 --> 00:02:09,310
You don't need to worry
too much about this.

35
00:02:09,310 --> 00:02:12,752
I just wanted to show how a Jupyter
notebook can integrate with the operating

36
00:02:12,752 --> 00:02:15,618
system to provide you with even
more tools to look at your data.

37
00:02:17,346 --> 00:02:20,490
We see from the cat output that
there seems to be a numeric list

38
00:02:20,490 --> 00:02:24,240
of columns followed by a bunch
of column identifiers.

39
00:02:24,240 --> 00:02:27,470
The column identifiers have some
odd looking characters in them.

40
00:02:27,470 --> 00:02:30,510
This is the unicode numero sign,
which means number of.

41
00:02:31,630 --> 00:02:33,990
Then we have rows of data,
all columns separated.

42
00:02:35,270 --> 00:02:38,170
We can read this into a DataFrame
by calling the read_csv

43
00:02:38,170 --> 00:02:40,200
function of the module.

44
00:02:40,200 --> 00:02:43,610
When we look at the DataFrame we see
that the first cell has an NaN in it

45
00:02:43,610 --> 00:02:47,320
since it's an empty value, and the rows
have been automatically indexed for us.

46
00:02:48,680 --> 00:02:51,890
It seems pretty clear that the first
row of data in the DataFrame is what

47
00:02:51,890 --> 00:02:53,390
we really want to see as the column names.

48
00:02:53,390 --> 00:02:57,500
It also seems like the first column
in the data is the country name,

49
00:02:57,500 --> 00:02:58,990
which we would like to make an index.

50
00:03:00,170 --> 00:03:04,060
Read csv has a number of parameters
that we can use to indicate

51
00:03:04,060 --> 00:03:06,429
to Pandas how rows and
columns should be labeled.

52
00:03:08,320 --> 00:03:13,380
For instance, we can use the index call to
indicate which column should be the index

53
00:03:13,380 --> 00:03:17,180
and we can also use the header parameter
to indicate which row from the data file

54
00:03:17,180 --> 00:03:19,010
should be used as the header.

55
00:03:19,010 --> 00:03:23,732
Let's re-import that data and center index
value to be 0 which is the first column

56
00:03:23,732 --> 00:03:27,458
and let set a column headers to be
read from the second row of data.

57
00:03:27,458 --> 00:03:30,060
We can do this by using
the skip rows parameters,

58
00:03:30,060 --> 00:03:34,316
to tell Pandas to ignore the first row,
which was made up of numeric column names.

59
00:03:36,758 --> 00:03:41,520
Now this data came from the all time
Olympic games medal table on Wikipedia.

60
00:03:41,520 --> 00:03:46,897
If we head to the page we could see
that instead of running gold, silver and

61
00:03:46,897 --> 00:03:51,839
bronze in the pages, these nice
little icons with a one, a two, and

62
00:03:51,839 --> 00:03:57,564
a three in them In our csv file these
were represented with the strings 01 !,

63
00:03:57,564 --> 00:03:59,090
02 !, and so on.

64
00:03:59,090 --> 00:04:03,510
We see that the column values are repeated
which really isn't good practice.

65
00:04:03,510 --> 00:04:08,759
Panda's recognize this in a panda.1 and
.2 to make things more unique.

66
00:04:09,950 --> 00:04:12,540
But this labeling isn't really
as clear as it could be, so

67
00:04:12,540 --> 00:04:14,570
we should clean up the data file.

68
00:04:14,570 --> 00:04:18,500
We can of course do this just by going and
editing the CSV file directly, but

69
00:04:18,500 --> 00:04:21,640
we can also set the column names
using the Pandas name property.

70
00:04:22,930 --> 00:04:27,090
Panda stores a list of all of
the columns in the .columns attribute.

71
00:04:27,090 --> 00:04:30,540
We can change the values of the column
names by iterating over this list and

72
00:04:30,540 --> 00:04:33,280
calling the rename method
of the data frame.

73
00:04:33,280 --> 00:04:36,650
Now, I'm going to copy and
paste this in to speed up things but

74
00:04:36,650 --> 00:04:38,400
we can walk through what is going on here.

75
00:04:39,600 --> 00:04:44,520
Here we just iterate through all
of the columns looking to see if

76
00:04:44,520 --> 00:04:47,830
they start with a 01, 02,
03 or numeric character.

77
00:04:47,830 --> 00:04:50,210
If they do, we can call rename and

78
00:04:50,210 --> 00:04:54,030
set the column parameters to a dictionary
with the keys being the column we want to

79
00:04:54,030 --> 00:04:56,630
replace and
the value being the new value we want.

80
00:04:57,700 --> 00:05:00,730
Here we'll slice some of
the old values in two,

81
00:05:00,730 --> 00:05:03,890
since we don't want to lose
the unique appended values.

82
00:05:03,890 --> 00:05:07,343
We'll also set the ever-important
in place parameter to true so

83
00:05:07,343 --> 00:05:09,991
Pandas knows to update
this data frame directly.

84
00:05:12,625 --> 00:05:16,191
All right, that's more on the data frame
with a focus on the workflow of actually

85
00:05:16,191 --> 00:05:19,660
getting data in and into a place
where we might want to query it.